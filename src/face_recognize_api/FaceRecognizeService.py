import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import pandas as pd
import numpy as np
import faiss
import cv2 as cv
from mtcnn import MTCNN
from keras_facenet import FaceNet

class FaceRecognizeService:
    def __init__(self, csv_path="./src/face_embeddings.csv"):
        # ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV
        self.df = pd.read_csv(csv_path)
        
        # L·∫•y nh√£n v√† vector embeddings
        self.labels = self.df["label"].values  # Nh√£n (t√™n th∆∞ m·ª•c)
        self.vectors = self.df.iloc[:, 1:].values.astype("float32")  # T·∫•t c·∫£ c·ªôt embedding (float32)
        
        # √Ånh x·∫° ch·ªâ s·ªë FAISS -> t√™n ng∆∞·ªùi
        self.index_to_name = {i: name for i, name in enumerate(self.labels)}
        
        # Kh·ªüi t·∫°o FAISS Index
        dimension = self.vectors.shape[1]  # S·ªë chi·ªÅu c·ªßa vector
        self.index = faiss.IndexFlatL2(dimension)  # D√πng L2 (Euclidean Distance)
        self.index.add(self.vectors)  # Th√™m vector v√†o FAISS
        
        # Kh·ªüi t·∫°o MTCNN v√† FaceNet
        self.detector = MTCNN()
        self.facenet = FaceNet()
        
        # Kh·ªüi t·∫°o VideoCapture
        self.capture = cv.VideoCapture(0)
    
    def recognize_face_faiss(self, face_vector, top_k=1, threshold=1.0):
        """
        T√¨m ng∆∞·ªùi g·∫ßn nh·∫•t v·ªõi face_vector b·∫±ng FAISS.
        N·∫øu kho·∫£ng c√°ch > threshold, tr·∫£ v·ªÅ 'Unknown'.
        """
        face_vector = np.array(face_vector).astype('float32').reshape(1, -1)
        D, I = self.index.search(face_vector, top_k)  # D: kho·∫£ng c√°ch, I: ch·ªâ s·ªë
        
        best_index = I[0][0]
        best_distance = D[0][0]
        
        if best_distance > threshold:
            return "Unknown", best_distance
        
        return self.index_to_name[best_index], best_distance
    
    def generate_face_embeddings(self, dataset_path="src/dataset", output_csv="face_embeddings.csv"):
        """
        Qu√©t th∆∞ m·ª•c dataset, tr√≠ch xu·∫•t embeddings v√† l∆∞u v√†o CSV.
        """
        data = []
        
        for root, dirs, files in os.walk(dataset_path):
            label = os.path.basename(root)  # L·∫•y t√™n th∆∞ m·ª•c l√†m nh√£n
            print(f"üìÇ ƒê·ªçc th∆∞ m·ª•c: {label}")

            for file in files:
                file_path = os.path.join(root, file)
                print(f"  üìÑ X·ª≠ l√Ω: {file_path}")
                
                img_bgr = cv.imread(file_path)
                if img_bgr is None:
                    print(f"‚ö†Ô∏è L·ªói ƒë·ªçc ·∫£nh: {file_path}")
                    continue
                
                img_rgb = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)
                results = self.detector.detect_faces(img_rgb)
                
                if results:
                    x, y, w, h = results[0]['box']
                    face_img = img_rgb[y:y+h, x:x+w]
                    
                    if face_img.shape[0] > 0 and face_img.shape[1] > 0:
                        face_img = cv.resize(face_img, (160, 160))
                        face_img = np.expand_dims(face_img, axis=0)
                        
                        ypred = self.facenet.embeddings(face_img)
                        data.append([label] + ypred.flatten().tolist())
        
        df = pd.DataFrame(data)
        df.columns = ["label"] + [f"dim_{i}" for i in range(df.shape[1] - 1)]
        df.to_csv(output_csv, index=False)
        
        print("‚úÖ ƒê√£ l∆∞u face_embeddings.csv th√†nh c√¥ng!")
    
    def start_camera(self):
        """
        B·∫Øt ƒë·∫ßu camera ƒë·ªÉ nh·∫≠n di·ªán khu√¥n m·∫∑t theo th·ªùi gian th·ª±c.
        """
        if not self.capture.isOpened():
            print("‚ùå Kh√¥ng th·ªÉ m·ªü camera")
            exit()

        frame_count = 1

        while True:
            ret, frame = self.capture.read()
            if not ret:
                print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh")
                break

            frame = cv.flip(frame, 1)  # L·∫≠t ngang gi·ªëng g∆∞∆°ng
            frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)  # Chuy·ªÉn BGR ‚Üí RGB
            results = self.detector.detect_faces(frame_rgb)
            
            if results:
                x, y, w, h = results[0]['box']
                cv.rectangle(frame_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)

                frame_count += 1
                face_img = frame[y: y+h, x: x+w]
                if face_img.shape[0] > 0 and face_img.shape[1] > 0 and frame_count % 10 == 0:
                    face_img = cv.resize(face_img, (160, 160))
                    face_img = np.expand_dims(face_img, axis=0)
                    ypred = self.facenet.embeddings(face_img)
                    frame_count = 1
                    predicted_name, confidence = self.recognize_face_faiss(ypred)
                    print(f"ƒê·ªëi t∆∞·ª£ng: {predicted_name}")
            
            frame_bgr = cv.cvtColor(frame_rgb, cv.COLOR_RGB2BGR)  # Chuy·ªÉn l·∫°i v·ªÅ BGR tr∆∞·ªõc khi hi·ªÉn th·ªã
            cv.imshow("Camera", frame_bgr)

            if cv.waitKey(1) & 0xFF == ord('q'):
                break

        self.capture.release()
        cv.destroyAllWindows()
